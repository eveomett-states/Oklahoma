{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import maup\n",
    "import time\n",
    "from maup import smart_repair\n",
    "from gerrychain import Graph\n",
    "\n",
    "maup.progress.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = Oklahoma\n",
    "state_ab = \"ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "1. Download all the data in directory \"ok_data\"\n",
    "2. Extract them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = state_ab + \"_data/\"\n",
    "population1_data = \"./{}{}_pl2020_b/{}_pl2020_p1_b.shp\".format(data_folder, state_ab, state_ab)\n",
    "population2_data = \"./{}{}_pl2020_b/{}_pl2020_p2_b.shp\".format(data_folder, state_ab, state_ab)\n",
    "vap_data =  \"./{}{}_pl2020_b/{}_pl2020_p4_b.shp\".format(data_folder, state_ab, state_ab)\n",
    "vest20_data = \"./{}{}_vest_20/{}_vest_20.shp\".format(data_folder, state_ab, state_ab)\n",
    "vest18_data = \"./{}{}_vest_18/{}_vest_18.shp\".format(data_folder, state_ab, state_ab)\n",
    "vest16_data = \"./{}{}_vest_16/{}_vest_16.shp\".format(data_folder, state_ab, state_ab)\n",
    "cd_data = \"./{}{}_cong_2021/ok_cong_2021.shp\".format(data_folder, state_ab)\n",
    "send_data = \"./{}{}_sldu_2021/ok_sldu_2021.shp\".format(data_folder, state_ab)\n",
    "hdist_data = \"./{}{}_sldl_2021/ok_sldl_2021.shp\".format(data_folder, state_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_smart_repair(df):\n",
    "    # change it to the UTM it needs for smart_repair\n",
    "    df = df.to_crs(df.estimate_utm_crs())\n",
    "    df = smart_repair(df)\n",
    "    if maup.doctor(df):\n",
    "        print('smart_repair successful')\n",
    "            \n",
    "        # change it back to this UTM for this data\n",
    "        df = df.to_crs('EPSG:4269')\n",
    "    else:\n",
    "        raise Exception('smart_repair failed')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_district(dist_df, dist_name, election_df, col_name):\n",
    "    # check if it needs to be smart_repair\n",
    "    if maup.doctor(dist_df) != True:\n",
    "        dist_df = do_smart_repair(dist_df)\n",
    "    \n",
    "    election_df = gpd.GeoDataFrame(election_df, crs=\"EPSG:4269\")\n",
    "    \n",
    "    # assign the pricincts\n",
    "    precincts_to_district_assignment = maup.assign(election_df.geometry, dist_df.geometry)\n",
    "    election_df[dist_name] = precincts_to_district_assignment\n",
    "    for precinct_index in range(len(election_df)):\n",
    "        election_df.at[precinct_index, dist_name] = dist_df.at[election_df.at[precinct_index, dist_name], col_name]\n",
    "    \n",
    "    return election_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(original, year):\n",
    "    party = original[6]\n",
    "    if party == 'R' or party == 'D':\n",
    "        return original[3:6] + year + original[6]\n",
    "    else:\n",
    "        return original[3:6] + year + 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_col = ['TOTPOP', 'HISP', 'NH_WHITE', 'NH_BLACK', 'NH_AMIN', 'NH_ASIAN', 'NH_NHPI', 'NH_OTHER', 'NH_2MORE', 'H_WHITE', 'H_BLACK', 'H_AMIN', 'H_ASIAN', 'H_NHPI', 'H_OTHER', 'H_2MORE', 'VAP', 'HVAP', 'WVAP', 'BVAP', 'AMINVAP', 'ASIANVAP', 'NHPIVAP', 'OTHERVAP', '2MOREVAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_population(population, df):\n",
    "    pop_check = pd.DataFrame({\n",
    "        'pop_col': pop_col,\n",
    "        'population_df': population[pop_col].sum(), \n",
    "        'vest_base': df[pop_col].sum(),\n",
    "        'equal': [x == y for x, y in zip(population[pop_col].sum(), df[pop_col].sum())]\n",
    "    })\n",
    "    if pop_check['equal'].mean() < 1:\n",
    "        print(pop_check)\n",
    "        raise Exception(\"population doesn't agree\")\n",
    "\n",
    "    else:\n",
    "        print(\"population agrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vest(vest, df, year, population, start_col):    \n",
    "     # check if it needs to be smart_repair\n",
    "    if maup.doctor(vest) != True:\n",
    "        vest = do_smart_repair(vest)\n",
    "    \n",
    "    # rename the columns\n",
    "    original_col = vest.columns[start_col:-1]\n",
    "    new_col = [rename(i, year) for i in original_col]\n",
    "    rename_dict = dict(zip(original_col, new_col))\n",
    "    vest = vest.rename(columns=rename_dict)\n",
    "    vest = vest.groupby(level=0, axis=1).sum() # combine all the other party's vote into columns with sufix \"O\"\n",
    "    col_name = list(set(new_col))\n",
    "    col_name.sort()\n",
    "    \n",
    "    # make the blocks from precincts by weight\n",
    "    vest = gpd.GeoDataFrame(vest, crs=\"EPSG:4269\")\n",
    "    election_in_block = population[[\"VAP\", 'geometry']] # population_df is in block scale\n",
    "    blocks_to_precincts_assignment = maup.assign(election_in_block.geometry, vest.geometry)\n",
    "\n",
    "    weights = election_in_block[\"VAP\"] / blocks_to_precincts_assignment.map(election_in_block[\"VAP\"].groupby(blocks_to_precincts_assignment).sum())\n",
    "    weights = weights.fillna(0)\n",
    "    prorated = maup.prorate(blocks_to_precincts_assignment, vest[col_name], weights)\n",
    "    election_in_block[col_name] = prorated\n",
    "\n",
    "    # assign blocks to precincts\n",
    "    election_in_block = gpd.GeoDataFrame(election_in_block, crs=\"EPSG:4269\")\n",
    "    df = gpd.GeoDataFrame(df, crs=\"EPSG:4269\")\n",
    "    block_to_pricinct_assginment = maup.assign(election_in_block.geometry, df.geometry)\n",
    "    df[col_name] = election_in_block[col_name].groupby(block_to_pricinct_assginment).sum()\n",
    "    df = df.groupby(level=0, axis=1).sum()\n",
    "    \n",
    "    # check if population agrees\n",
    "    check_population(population, df)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "population1_df = gpd.read_file(population1_data)\n",
    "population2_df = gpd.read_file(population2_data)\n",
    "vap_df = gpd.read_file(vap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "population2_df = population2_df.drop(columns=['SUMLEV', 'LOGRECNO', 'GEOID', 'COUNTY', 'geometry'])\n",
    "vap_df = vap_df.drop(columns=['SUMLEV', 'LOGRECNO', 'GEOID', 'COUNTY', 'geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = pd.merge(population1_df, population2_df, on='GEOID20')\n",
    "population_df = pd.merge(population_df, vap_df, on='GEOID20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180154/180154 [02:55<00:00, 1027.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maup.doctor(population_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df['H_WHITE'] = population_df.apply(lambda t: t['P0010003'] - t['P0020005'], 1)\n",
    "population_df['H_BLACK'] = population_df.apply(lambda t: t['P0010004'] - t['P0020006'], 1)\n",
    "population_df['H_AMIN'] = population_df.apply(lambda t: t['P0010005'] - t['P0020007'], 1)\n",
    "population_df['H_ASIAN'] = population_df.apply(lambda t: t['P0010006'] - t['P0020008'], 1)\n",
    "population_df['H_NHPI'] = population_df.apply(lambda t: t['P0010007'] - t['P0020009'], 1)\n",
    "population_df['H_OTHER'] = population_df.apply(lambda t: t['P0010008'] - t['P0020010'], 1)\n",
    "population_df['H_2MORE'] = population_df.apply(lambda t: t['P0010009'] - t['P0020011'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {'P0020001': 'TOTPOP', 'P0020002': 'HISP', 'P0020005': 'NH_WHITE', 'P0020006': 'NH_BLACK', 'P0020007': 'NH_AMIN',\n",
    "                    'P0020008': 'NH_ASIAN', 'P0020009': 'NH_NHPI', 'P0020010': 'NH_OTHER', 'P0020011': 'NH_2MORE',\n",
    "                    'P0040001': 'VAP', 'P0040002': 'HVAP', 'P0040005': 'WVAP', 'P0040006': 'BVAP', 'P0040007': 'AMINVAP',\n",
    "                                        'P0040008': 'ASIANVAP', 'P0040009': 'NHPIVAP', 'P0040010': 'OTHERVAP', 'P0040011': '2MOREVAP'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df.rename(columns=rename_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 35.16it/s]\n"
     ]
    }
   ],
   "source": [
    "cong_df = gpd.read_file(cd_data)\n",
    "if maup.doctor(cong_df) != True:\n",
    "    cong_df = do_smart_repair(cong_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the vest 20 data\n",
    "\n",
    "Now using it as a \"base pricinct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vest_base(vest, start_col, year):\n",
    "    original_col = vest.columns[start_col:-1]\n",
    "    new_col = [rename(i, year) for i in original_col]\n",
    "    rename_dict = dict(zip(original_col, new_col))\n",
    "    vest = vest.rename(columns=rename_dict)\n",
    "    vest = vest.groupby(level=0, axis=1).sum()\n",
    "    vest = gpd.GeoDataFrame(vest, crs=\"EPSG:4269\")\n",
    "    \n",
    "    return vest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if vest20 can be used as base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1948/1948 [00:05<00:00, 384.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16 overlaps.\n",
      "There are 40 holes.\n",
      "There are some invalid geometries.\n",
      "Snapping all geometries to a grid with precision 10^( -5 ) to avoid GEOS errors.\n",
      "Identifying overlaps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2038/2038 [00:01<00:00, 1726.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving overlaps...\n",
      "Assigning order 2 pieces...\n",
      "Filling gaps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gaps to simplify: 100%|██████████| 44/44 [00:07<00:00,  5.52it/s]\n",
      "Gaps to fill: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "100%|██████████| 1948/1948 [00:04<00:00, 425.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smart_repair successful\n"
     ]
    }
   ],
   "source": [
    "vest20 = gpd.read_file(vest20_data)\n",
    "if maup.doctor(vest20) != True:\n",
    "    vest20 = do_smart_repair(vest20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATEFP', 'COUNTYFP', 'COUNTY_NAM', 'PCT_CEB', 'GEOID', 'G20PRERTRU',\n",
       "       'G20PREDBID', 'G20PRELJOR', 'G20PREIWES', 'G20PREISIM', 'G20PREIPIE',\n",
       "       'G20USSRINH', 'G20USSDBRO', 'G20USSLMUR', 'G20USSIFAR', 'G20USSINES',\n",
       "       'G20COCRHIE', 'G20COCLHAG', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vest20.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_col = 5\n",
    "vest_base_data = vest20\n",
    "year = '20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest_base = add_vest_base(vest_base_data, start_col, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1948/1948 [00:06<00:00, 321.55it/s]\n",
      "100%|██████████| 1948/1948 [00:16<00:00, 116.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# vap and population have the same GEOID20\n",
    "blocks_to_precincts_assignment = maup.assign(population_df.geometry, vest_base.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest_base[pop_col] = population_df[pop_col].groupby(blocks_to_precincts_assignment).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df = gpd.GeoDataFrame(vest_base, crs=\"EPSG:4269\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COC20O', 'COC20R', 'COUNTYFP', 'COUNTY_NAM', 'GEOID', 'PCT_CEB',\n",
       "       'PRE20D', 'PRE20O', 'PRE20R', 'STATEFP', 'USS20D', 'USS20O', 'USS20R',\n",
       "       'geometry', 'TOTPOP', 'HISP', 'NH_WHITE', 'NH_BLACK', 'NH_AMIN',\n",
       "       'NH_ASIAN', 'NH_NHPI', 'NH_OTHER', 'NH_2MORE', 'H_WHITE', 'H_BLACK',\n",
       "       'H_AMIN', 'H_ASIAN', 'H_NHPI', 'H_OTHER', 'H_2MORE', 'VAP', 'HVAP',\n",
       "       'WVAP', 'BVAP', 'AMINVAP', 'ASIANVAP', 'NHPIVAP', 'OTHERVAP',\n",
       "       '2MOREVAP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "election_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if population agrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop_col</th>\n",
       "      <th>population_df</th>\n",
       "      <th>vest_base</th>\n",
       "      <th>equal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TOTPOP</th>\n",
       "      <td>TOTPOP</td>\n",
       "      <td>3959353</td>\n",
       "      <td>3959344</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISP</th>\n",
       "      <td>HISP</td>\n",
       "      <td>471931</td>\n",
       "      <td>471931</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH_WHITE</th>\n",
       "      <td>NH_WHITE</td>\n",
       "      <td>2407188</td>\n",
       "      <td>2407185</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH_BLACK</th>\n",
       "      <td>NH_BLACK</td>\n",
       "      <td>283242</td>\n",
       "      <td>283242</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH_AMIN</th>\n",
       "      <td>NH_AMIN</td>\n",
       "      <td>311890</td>\n",
       "      <td>311884</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH_ASIAN</th>\n",
       "      <td>NH_ASIAN</td>\n",
       "      <td>89653</td>\n",
       "      <td>89653</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH_NHPI</th>\n",
       "      <td>NH_NHPI</td>\n",
       "      <td>8168</td>\n",
       "      <td>8168</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH_OTHER</th>\n",
       "      <td>NH_OTHER</td>\n",
       "      <td>13602</td>\n",
       "      <td>13602</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH_2MORE</th>\n",
       "      <td>NH_2MORE</td>\n",
       "      <td>373679</td>\n",
       "      <td>373679</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_WHITE</th>\n",
       "      <td>H_WHITE</td>\n",
       "      <td>107697</td>\n",
       "      <td>107697</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_BLACK</th>\n",
       "      <td>H_BLACK</td>\n",
       "      <td>6719</td>\n",
       "      <td>6719</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_AMIN</th>\n",
       "      <td>H_AMIN</td>\n",
       "      <td>20901</td>\n",
       "      <td>20901</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_ASIAN</th>\n",
       "      <td>H_ASIAN</td>\n",
       "      <td>1296</td>\n",
       "      <td>1296</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_NHPI</th>\n",
       "      <td>H_NHPI</td>\n",
       "      <td>440</td>\n",
       "      <td>440</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_OTHER</th>\n",
       "      <td>H_OTHER</td>\n",
       "      <td>200399</td>\n",
       "      <td>200399</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_2MORE</th>\n",
       "      <td>H_2MORE</td>\n",
       "      <td>134479</td>\n",
       "      <td>134479</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAP</th>\n",
       "      <td>VAP</td>\n",
       "      <td>3010698</td>\n",
       "      <td>3010689</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HVAP</th>\n",
       "      <td>HVAP</td>\n",
       "      <td>295621</td>\n",
       "      <td>295621</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WVAP</th>\n",
       "      <td>WVAP</td>\n",
       "      <td>1963854</td>\n",
       "      <td>1963851</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BVAP</th>\n",
       "      <td>BVAP</td>\n",
       "      <td>212976</td>\n",
       "      <td>212976</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMINVAP</th>\n",
       "      <td>AMINVAP</td>\n",
       "      <td>219638</td>\n",
       "      <td>219632</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASIANVAP</th>\n",
       "      <td>ASIANVAP</td>\n",
       "      <td>69282</td>\n",
       "      <td>69282</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NHPIVAP</th>\n",
       "      <td>NHPIVAP</td>\n",
       "      <td>5082</td>\n",
       "      <td>5082</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHERVAP</th>\n",
       "      <td>OTHERVAP</td>\n",
       "      <td>10012</td>\n",
       "      <td>10012</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2MOREVAP</th>\n",
       "      <td>2MOREVAP</td>\n",
       "      <td>234233</td>\n",
       "      <td>234233</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pop_col  population_df  vest_base  equal\n",
       "TOTPOP      TOTPOP        3959353    3959344  False\n",
       "HISP          HISP         471931     471931   True\n",
       "NH_WHITE  NH_WHITE        2407188    2407185  False\n",
       "NH_BLACK  NH_BLACK         283242     283242   True\n",
       "NH_AMIN    NH_AMIN         311890     311884  False\n",
       "NH_ASIAN  NH_ASIAN          89653      89653   True\n",
       "NH_NHPI    NH_NHPI           8168       8168   True\n",
       "NH_OTHER  NH_OTHER          13602      13602   True\n",
       "NH_2MORE  NH_2MORE         373679     373679   True\n",
       "H_WHITE    H_WHITE         107697     107697   True\n",
       "H_BLACK    H_BLACK           6719       6719   True\n",
       "H_AMIN      H_AMIN          20901      20901   True\n",
       "H_ASIAN    H_ASIAN           1296       1296   True\n",
       "H_NHPI      H_NHPI            440        440   True\n",
       "H_OTHER    H_OTHER         200399     200399   True\n",
       "H_2MORE    H_2MORE         134479     134479   True\n",
       "VAP            VAP        3010698    3010689  False\n",
       "HVAP          HVAP         295621     295621   True\n",
       "WVAP          WVAP        1963854    1963851  False\n",
       "BVAP          BVAP         212976     212976   True\n",
       "AMINVAP    AMINVAP         219638     219632  False\n",
       "ASIANVAP  ASIANVAP          69282      69282   True\n",
       "NHPIVAP    NHPIVAP           5082       5082   True\n",
       "OTHERVAP  OTHERVAP          10012      10012   True\n",
       "2MOREVAP  2MOREVAP         234233     234233   True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'pop_col': pop_col,\n",
    "    'population_df': population_df[pop_col].sum(), \n",
    "    'vest_base': vest_base[pop_col].sum(),\n",
    "    'equal': [x == y for x, y in zip(population_df[pop_col].sum(), vest_base[pop_col].sum())]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add more vest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vest18 = gpd.read_file(vest18_data)\n",
    "vest16 = gpd.read_file(vest16_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COUNTY', 'PRECINCT', 'PCT_CEB', 'G18GOVRSTI', 'G18GOVDEDM',\n",
       "       'G18GOVLPOW', 'G18LTGRPIN', 'G18LTGDPIT', 'G18LTGIHOL', 'G18ATGRHUN',\n",
       "       'G18ATGDMYL', 'G18TRERMCD', 'G18TREICOU', 'G18AUDRBYR', 'G18AUDLYEU',\n",
       "       'G18LABROSB', 'G18LABDDOR', 'G18LABIDIS', 'G18COCRANT', 'G18COCDMCC',\n",
       "       'G18COCISHO', 'G18INSRMUL', 'G18INSDFOB', 'G18SPIRHOF', 'G18SPIDCOX',\n",
       "       'G18SPIIHUF', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vest18.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COUNTY', 'PRECINCT', 'PCT_CEB', 'G16PRERTRU', 'G16PREDCLI',\n",
       "       'G16PRELJOH', 'G16USSRLAN', 'G16USSDWOR', 'G16USSLMUR', 'G16USSIBRA',\n",
       "       'G16USSIBEA', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vest16.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [00:06<00:00, 303.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 90 overlaps.\n",
      "There are 954 holes.\n",
      "There are some invalid geometries.\n",
      "Snapping all geometries to a grid with precision 10^( -5 ) to avoid GEOS errors.\n",
      "Identifying overlaps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3929/3929 [00:02<00:00, 1595.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving overlaps...\n",
      "Assigning order 2 pieces...\n",
      "Filling gaps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gaps to simplify: 100%|██████████| 966/966 [03:26<00:00,  4.69it/s]\n",
      "Gaps to fill: 100%|██████████| 31/31 [00:11<00:00,  2.77it/s]\n",
      "100%|██████████| 1951/1951 [00:04<00:00, 425.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smart_repair successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [00:05<00:00, 326.88it/s]\n",
      "100%|██████████| 1951/1951 [00:24<00:00, 80.57it/s] \n",
      "100%|██████████| 1948/1948 [00:05<00:00, 345.34it/s]\n",
      "100%|██████████| 1948/1948 [00:16<00:00, 120.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           pop_col  population_df  vest_base  equal\n",
      "TOTPOP      TOTPOP        3959353    3959344  False\n",
      "HISP          HISP         471931     471931   True\n",
      "NH_WHITE  NH_WHITE        2407188    2407185  False\n",
      "NH_BLACK  NH_BLACK         283242     283242   True\n",
      "NH_AMIN    NH_AMIN         311890     311884  False\n",
      "NH_ASIAN  NH_ASIAN          89653      89653   True\n",
      "NH_NHPI    NH_NHPI           8168       8168   True\n",
      "NH_OTHER  NH_OTHER          13602      13602   True\n",
      "NH_2MORE  NH_2MORE         373679     373679   True\n",
      "H_WHITE    H_WHITE         107697     107697   True\n",
      "H_BLACK    H_BLACK           6719       6719   True\n",
      "H_AMIN      H_AMIN          20901      20901   True\n",
      "H_ASIAN    H_ASIAN           1296       1296   True\n",
      "H_NHPI      H_NHPI            440        440   True\n",
      "H_OTHER    H_OTHER         200399     200399   True\n",
      "H_2MORE    H_2MORE         134479     134479   True\n",
      "VAP            VAP        3010698    3010689  False\n",
      "HVAP          HVAP         295621     295621   True\n",
      "WVAP          WVAP        1963854    1963851  False\n",
      "BVAP          BVAP         212976     212976   True\n",
      "AMINVAP    AMINVAP         219638     219632  False\n",
      "ASIANVAP  ASIANVAP          69282      69282   True\n",
      "NHPIVAP    NHPIVAP           5082       5082   True\n",
      "OTHERVAP  OTHERVAP          10012      10012   True\n",
      "2MOREVAP  2MOREVAP         234233     234233   True\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "population doesn't agree",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/aagarwal/Desktop/Redestring AI/Oklahoma/ok.ipynb Cell 38\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# check the result here\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X53sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m election_df \u001b[39m=\u001b[39m add_vest(vest18, election_df, \u001b[39m'\u001b[39m\u001b[39m18\u001b[39m\u001b[39m'\u001b[39m, population_df, \u001b[39m3\u001b[39m)\n",
      "\u001b[1;32m/Users/aagarwal/Desktop/Redestring AI/Oklahoma/ok.ipynb Cell 38\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X53sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby(level\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msum()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X53sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# check if population agrees\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X53sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m check_population(population, df)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X53sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "\u001b[1;32m/Users/aagarwal/Desktop/Redestring AI/Oklahoma/ok.ipynb Cell 38\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X53sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m pop_check[\u001b[39m'\u001b[39m\u001b[39mequal\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmean() \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X53sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(pop_check)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X53sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mpopulation doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt agree\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X53sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X53sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpopulation agrees\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: population doesn't agree"
     ]
    }
   ],
   "source": [
    "# check the result here\n",
    "election_df = add_vest(vest18, election_df, '18', population_df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COC20O', 'COC20R', 'COUNTYFP', 'COUNTY_NAM', 'GEOID', 'PCT_CEB',\n",
       "       'PRE20D', 'PRE20O', 'PRE20R', 'STATEFP', 'USS20D', 'USS20O', 'USS20R',\n",
       "       'geometry', 'TOTPOP', 'HISP', 'NH_WHITE', 'NH_BLACK', 'NH_AMIN',\n",
       "       'NH_ASIAN', 'NH_NHPI', 'NH_OTHER', 'NH_2MORE', 'H_WHITE', 'H_BLACK',\n",
       "       'H_AMIN', 'H_ASIAN', 'H_NHPI', 'H_OTHER', 'H_2MORE', 'VAP', 'HVAP',\n",
       "       'WVAP', 'BVAP', 'AMINVAP', 'ASIANVAP', 'NHPIVAP', 'OTHERVAP',\n",
       "       '2MOREVAP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "election_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1956/1956 [00:05<00:00, 332.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 77 overlaps.\n",
      "There are 895 holes.\n",
      "There are some invalid geometries.\n",
      "Snapping all geometries to a grid with precision 10^( -5 ) to avoid GEOS errors.\n",
      "Identifying overlaps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3886/3886 [00:02<00:00, 1503.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving overlaps...\n",
      "Assigning order 2 pieces...\n",
      "Filling gaps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gaps to simplify: 100%|██████████| 943/943 [03:15<00:00,  4.82it/s]\n",
      "Gaps to fill: 100%|██████████| 31/31 [00:10<00:00,  2.82it/s]\n",
      "100%|██████████| 1956/1956 [00:04<00:00, 451.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smart_repair successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1956/1956 [00:05<00:00, 328.86it/s]\n",
      "100%|██████████| 1956/1956 [00:24<00:00, 80.15it/s] \n",
      "100%|██████████| 1948/1948 [00:05<00:00, 348.81it/s]\n",
      "100%|██████████| 1948/1948 [00:15<00:00, 127.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           pop_col  population_df  vest_base  equal\n",
      "TOTPOP      TOTPOP        3959353    3959344  False\n",
      "HISP          HISP         471931     471931   True\n",
      "NH_WHITE  NH_WHITE        2407188    2407185  False\n",
      "NH_BLACK  NH_BLACK         283242     283242   True\n",
      "NH_AMIN    NH_AMIN         311890     311884  False\n",
      "NH_ASIAN  NH_ASIAN          89653      89653   True\n",
      "NH_NHPI    NH_NHPI           8168       8168   True\n",
      "NH_OTHER  NH_OTHER          13602      13602   True\n",
      "NH_2MORE  NH_2MORE         373679     373679   True\n",
      "H_WHITE    H_WHITE         107697     107697   True\n",
      "H_BLACK    H_BLACK           6719       6719   True\n",
      "H_AMIN      H_AMIN          20901      20901   True\n",
      "H_ASIAN    H_ASIAN           1296       1296   True\n",
      "H_NHPI      H_NHPI            440        440   True\n",
      "H_OTHER    H_OTHER         200399     200399   True\n",
      "H_2MORE    H_2MORE         134479     134479   True\n",
      "VAP            VAP        3010698    3010689  False\n",
      "HVAP          HVAP         295621     295621   True\n",
      "WVAP          WVAP        1963854    1963851  False\n",
      "BVAP          BVAP         212976     212976   True\n",
      "AMINVAP    AMINVAP         219638     219632  False\n",
      "ASIANVAP  ASIANVAP          69282      69282   True\n",
      "NHPIVAP    NHPIVAP           5082       5082   True\n",
      "OTHERVAP  OTHERVAP          10012      10012   True\n",
      "2MOREVAP  2MOREVAP         234233     234233   True\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "population doesn't agree",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/aagarwal/Desktop/Redestring AI/Oklahoma/ok.ipynb Cell 40\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m election_df \u001b[39m=\u001b[39m add_vest(vest16, election_df, \u001b[39m'\u001b[39m\u001b[39m16\u001b[39m\u001b[39m'\u001b[39m, population_df, \u001b[39m3\u001b[39m)\n",
      "\u001b[1;32m/Users/aagarwal/Desktop/Redestring AI/Oklahoma/ok.ipynb Cell 40\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X55sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby(level\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msum()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X55sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# check if population agrees\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X55sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m check_population(population, df)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X55sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "\u001b[1;32m/Users/aagarwal/Desktop/Redestring AI/Oklahoma/ok.ipynb Cell 40\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X55sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m pop_check[\u001b[39m'\u001b[39m\u001b[39mequal\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmean() \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X55sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(pop_check)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X55sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mpopulation doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt agree\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X55sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aagarwal/Desktop/Redestring%20AI/Oklahoma/ok.ipynb#X55sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpopulation agrees\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: population doesn't agree"
     ]
    }
   ],
   "source": [
    "election_df = add_vest(vest16, election_df, '16', population_df, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Add the district data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send = gpd.read_file(send_data)\n",
    "hdist = gpd.read_file(hdist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df = add_district(cong_df, \"CD\", election_df, \"DISTRICT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df = add_district(send, \"SEND\", election_df, \"DISTRICT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdist = hdist.to_crs(\"EPSG:4269\")\n",
    "election_df = add_district(hdist, \"HDIST\", election_df, \"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put the base precinct year after the precinct information column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_columns = {}\n",
    "if 'COUNTYFP' + year not in election_df.columns:\n",
    "    base_columns = {\n",
    "        'STATEFP':'STATEFP'+year,\n",
    "        'COUNTYFP':'COUNTYFP'+year,\n",
    "        'COUNTY_NAM':'COUNTY_NAM'+year,\n",
    "        'PCT_CEB':'PCT_CEB'+year,\n",
    "        'GEOID':'GEOID'+year}\n",
    "election_df.rename(columns=base_columns, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the columns\n",
    "fixed_columns = [\n",
    "    'STATEFP'+year,\n",
    "    'COUNTYFP'+year,\n",
    "    'COUNTY_NAM'+year,\n",
    "    'PCT_CEB'+year,\n",
    "    'GEOID'+year,\n",
    "    'CD',\n",
    "    'SEND',\n",
    "    'HDIST',\n",
    "    'TOTPOP',\n",
    "    'NH_2MORE',\n",
    "    'NH_AMIN',\n",
    "    'NH_ASIAN',\n",
    "    'NH_BLACK',\n",
    "    'NH_NHPI',\n",
    "    'NH_OTHER',\n",
    "    'NH_WHITE',\n",
    "    'HISP',\n",
    "    'H_AMIN',\n",
    "    'H_ASIAN',\n",
    "    'H_BLACK',\n",
    "    'H_NHPI',\n",
    "    'H_OTHER',\n",
    "    'H_WHITE',\n",
    "    'H_2MORE',\n",
    "    'VAP',\n",
    "    'HVAP',\n",
    "    'WVAP',\n",
    "    'BVAP',\n",
    "    'AMINVAP',\n",
    "    'ASIANVAP',\n",
    "    'NHPIVAP',\n",
    "    'OTHERVAP',\n",
    "    '2MOREVAP']\n",
    "\n",
    "election_columns = [col for col in election_df.columns if col not in fixed_columns]\n",
    "final_col = fixed_columns + election_columns\n",
    "election_df = election_df[final_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# store the result in directory \"il\"\n",
    "directory = \"./{}\".format(state_ab)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "shapefile_path = \"./{}/{}.shp\".format(state_ab, state_ab)\n",
    "geojson_path = './{}/{}.geojson'.format(state_ab, state_ab)\n",
    "json_path = \"./{}/{}.json\".format(state_ab, state_ab)\n",
    "\n",
    "# Check if the shapefile or geojson file already exists\n",
    "if os.path.exists(shapefile_path):\n",
    "    os.remove(shapefile_path)\n",
    "if os.path.exists(geojson_path):\n",
    "    os.remove(geojson_path)\n",
    "\n",
    "election_df.to_file(shapefile_path)\n",
    "election_df.to_file(geojson_path, driver='GeoJSON')\n",
    "\n",
    "# Only do once to build json and read from file when generating ensembles\n",
    "graph = Graph.from_file(shapefile_path, ignore_errors=True)\n",
    "graph.to_json(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile_path = \"./{}/{}.shp\".format(state_ab, state_ab)\n",
    "shape=gpd.read_file(shapefile_path)\n",
    "shape.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gerry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
